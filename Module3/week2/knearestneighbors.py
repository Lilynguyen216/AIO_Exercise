# -*- coding: utf-8 -*-
"""KNearestNeighbors.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x9zEsupE7rbOAHQXlaKK1QVgR6HF_t15
"""

!pip install --upgrade pyarrow

!pip install -q datasets

!pip uninstall -y pyarrow datasets
!pip install pyarrow datasets

import numpy as np
import matplotlib.pyplot as plt

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.feature_extraction.text import CountVectorizer
from datasets import load_dataset
from sklearn.datasets import load_iris

#Load the diabetes dataset
iris_X, iris_y = datasets.load_iris(return_X_y=True)

#Split train:test = 8:2
X_train, X_test, y_train, y_test = train_test_split(
    iris_X,
    iris_y,
    test_size=0.2,
    random_state=42
)

#Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Build KNN Classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5)
knn_classifier.fit(X_train, y_train)

#Predict and Evaluate test set
y_pred = knn_classifier.predict(X_test)
accuracy_score = (y_test, y_pred)
accuracy_score

# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y = True)

# train test split
X_train, X_test, y_train, y_test = train_test_split(
    diabetes_X,
    diabetes_y,
    test_size=0.2,
    random_state=42
)

# Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build KNN Regressor model
knn_regressor = KNeighborsRegressor()
knn_regressor.fit(X_train, y_train)

#Predict and Evaluate test set
y_pred = knn_regressor.predict(X_test)
accuracy_score = (y_test, y_pred)
accuracy_score

# Load IMDB dataset
imdb = load_dataset('imdb')
imdb_train, imdb_test = imdb['train'], imdb['test']

# Convert text to vector using BoW
vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(imdb_train['text']).toarray()
X_test = vectorizer.transform(imdb_test['text']).toarray()

# Convert labels to numpy arrays
y_train = np.array(imdb_train['label'])
y_test = np.array(imdb_test['label'])

# Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build KNN Classifier
knn_classifier = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree')
knn_classifier.fit(X_train, y_train)

# predict test set and evaluate
y_pred = knn_classifier.predict(X_test)
accuracy_score = (y_test, y_pred)
accuracy_score

iris_dataset = load_iris()
data = iris_dataset.data[:, :2]

# Plot data
plt.scatter(data[:, 0], data[:, 1], c='gray')
plt.title('Initial Dataset')
plt.xlabel('Sepal length (cm)')
plt.ylabel('Sepal width (cm)')
plt.show()

class KMeans:
  def __init__(self, k=3, max_iters=100):
    self.k = k
    self.max_iters = max_iters
    self.centroids = None
    self.clusters = None

  def initialize_centroids(self, data):
    np.random.seed(42)
    self.centroids = data[np.random.choice(data.shape[0], self.k, replace=False)]

  def euclidean_distance(self, x1, x2):
    return np.sqrt(np.sum(np.power(x1-x2, 2)))

  def assign_clusters(self, data):
    distances = np.array([[self.euclidean_distance(x, centroid) for centroid in self.centroids]
                          for x in data])
    return np.argmin(distances, axis=1)

  def update_centroids(self, data):
    new_centroids = np.array([np.mean(data[self.clusters == i], axis=0) for i in range(self.k)])
    return new_centroids

  def fit(self, data):
    self.initialize_centroids(data)

    for _ in range(self.max_iters):
      self.clusters = self.assign_clusters(data)
      self.plot_clusters(data, _)
      new_centroids = self.update_centroids(data)
      if np.all(self.centroids == new_centroids):
        break
      self.centroids = new_centroids
    self.plot_final_clusters(data)

  def plot_clusters(self, data, iteration):
    plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o', alpha=0.6)
    plt.scatter(self.centroids[:, 0], self.centroids[:, 1], c='red', marker='x', s=300)
    plt.title(f'Iteration {iteration + 1}')
    plt.xlabel('Sepal length (cm)')
    plt.ylabel('Sepal width (cm)')
    plt.show()

  def plot_final_clusters(self, data):
    plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o', alpha=0.6)
    plt.scatter(self.centroids[:, 0], self.centroids[:, 1], c='red', marker='x', s=300)
    plt.title('Final Clusters and Centroids')
    plt.xlabel('Sepal length (cm)')
    plt.ylabel('Sepal width (cm)')
    plt.show()

kmeans = KMeans(k=2)
kmeans.fit(data)

kmeans = KMeans(k=3)
kmeans.fit(data)

kmeans = KMeans(k=4)
kmeans.fit(data)